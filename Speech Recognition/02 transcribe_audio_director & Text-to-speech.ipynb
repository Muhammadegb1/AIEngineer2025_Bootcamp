{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d142e7c9-ef63-47ff-964a-75ebe6ad5130",
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "\n",
    "import csv\n",
    "import os\n",
    "\n",
    "from gtts import gTTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3577410-ecfa-40f8-88b5-c98d4eb513db",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = whisper.load_model(\"base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493bf1bc-cf9a-49b9-8f45-1bc70c629a6b",
   "metadata": {},
   "source": [
    "# Transcribing Multiple Audio Files from a Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0a9c15a-252f-4be6-8def-2565df1377b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path = \"C:/Users/asus/Downloads/Recordings/Recordings\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17dc5c54-8d9e-4705-8827-02895fa2cd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_directory_whisper(directory_path):\n",
    "    transcriptions = []\n",
    "    for file_name in os.listdir(directory_path):\n",
    "        if file_name.endswith(\".wav\"):\n",
    "            files_path = os.path.join(directory_path, file_name)\n",
    "            # Transcribe the audio file\n",
    "            result = model.transcribe(files_path)\n",
    "            transcription = result[\"text\"]\n",
    "            transcriptions.append({\"file_name\": file_name, \"transcription\": transcription})\n",
    "    return transcriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "033c5291-4ff8-4884-be96-eff5df3cbe1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asus\\miniconda3\\envs\\speech_env\\Lib\\site-packages\\whisper\\transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    }
   ],
   "source": [
    "transcriptions = transcribe_directory_whisper(directory_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5bb00665-d507-4bb4-b233-09ab8ab0a6e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'file_name': 'Track1.wav',\n",
       "  'transcription': \" I'm a sound engineer turned data scientist. Curious about machine learning and artificial intelligence.\"},\n",
       " {'file_name': 'Track2.wav',\n",
       "  'transcription': ' My professional background is primarily in media production with a focus on audio, IT, and communications.'},\n",
       " {'file_name': 'Track3.wav',\n",
       "  'transcription': \" Over the years, I've developed a strong interest in digital signal processing sound and music computing.\"},\n",
       " {'file_name': 'Track4.wav',\n",
       "  'transcription': ' As a graduate of Sound Engineering, I make it a priority to strike a balance between art and technology and my work.'},\n",
       " {'file_name': 'Track5.wav',\n",
       "  'transcription': ' I believe that nowadays, data is the key to everything.'},\n",
       " {'file_name': 'Track6.wav',\n",
       "  'transcription': ' Not only can it provide a rational explanation for complicated scientific puzzles.'},\n",
       " {'file_name': 'Track7.wav',\n",
       "  'transcription': ' But it can also give you efficient methodologies for solving problems.'},\n",
       " {'file_name': 'Track8.wav',\n",
       "  'transcription': \" From the website cookies you've been asked to accept while surfing the web to the sonification of a super massive black hole.\"}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d532b8-204d-428c-b05e-5613339da7bf",
   "metadata": {},
   "source": [
    "# Saving Audio Transcriptions to CSV for Easy Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d21ed04-72df-40cb-9236-da09c846bcea",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = \"transcriptions.csv\"\n",
    "\n",
    "with open(output_file, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Track Number\", \"File Name\", \"Transcription\"])  # Write the header\n",
    "    for number, transcription in enumerate(transcriptions, start=1):\n",
    "        writer.writerow([number, transcription['file_name'], transcription['transcription']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645a410b-2314-4dd9-a866-bf7d74dec35b",
   "metadata": {},
   "source": [
    "# Text-to-Speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b28d189a-9e0c-4bfb-bbd4-e1a7f22d8c08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"\"\"Thank you for taking the time to watch our course on speech recognition!\n",
    "This concludes the final lesson of this section. See you soon!\"\"\"\n",
    "\n",
    "tts = gTTS(text=text, lang='en')\n",
    "tts.save(\"output.mp3\")\n",
    "\n",
    "os.system(\"start output.mp3\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(speech_env)",
   "language": "python",
   "name": "speech_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
